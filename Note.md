* Fast ai
* Train net on MNIST and CIFAR
* Start with lenet, alexnet



__Insight from papers__

* The more data in the training dataset is associated with a given class, the lower the attack precision for that class.
* overfitting is not the only factor that causes a model to be vulnerable to membership inference.



Overfit => réduire le nombre de paramètre jusqu'à que ça marche



augmenter overfit: reduire données ou plus de paramètres



plotter distribution des deux populations

$\phi(x)=G_1(x)-G_0(x)$



Check G classe comme test => F se casse la gueule. Justifie l'utilisation de G comme régulatisateur



G: resnet



Faire tourner de temps en temps du cifar: => code générique



